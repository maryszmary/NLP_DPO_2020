{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z6ccN1AlFhNo"
   },
   "source": [
    "## Классификация текста с использованием CNN\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1U3vnZeD8aiDg5Gh-SjnEyJyfrTHSRTkB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oJ8_zAI8FhNp"
   },
   "source": [
    "Используя данные отзывов IMDB, построим CNN для классификации документов на позитивный и негативный классы.\n",
    "\n",
    "Источник изложения: https://github.com/bentrevett/pytorch-sentiment-analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NHKLq9hEFhNr"
   },
   "source": [
    "В предположении, что PyTorch уже установлен, поставим дополнительные модули и загрузим модель для токенизации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GgGxeuQjG9NI"
   },
   "outputs": [],
   "source": [
    "# !pip3 install https://download.pytorch.org/whl/cpu/torch-1.0.1.post2-cp36-cp36m-linux_x86_64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# если всё-таки надо поставить torch\n",
    "# !pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 126
    },
    "colab_type": "code",
    "id": "5kiZro9eG-bG",
    "outputId": "0c9354b0-67b8-4ed4-cf4f-b9189ddbf7b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchvision\n",
      "  Downloading torchvision-0.5.0-cp36-cp36m-manylinux1_x86_64.whl (4.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.0 MB 86 kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting pillow>=4.1.1\n",
      "  Downloading Pillow-7.1.1-cp36-cp36m-manylinux1_x86_64.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 10.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: torch==1.4.0 in /home/maryszmary/.local/share/virtualenvs/NLP_DPO_2020-U6tis9ju/lib/python3.6/site-packages (from torchvision) (1.4.0)\n",
      "Requirement already satisfied: six in /home/maryszmary/.local/share/virtualenvs/NLP_DPO_2020-U6tis9ju/lib/python3.6/site-packages (from torchvision) (1.14.0)\n",
      "Requirement already satisfied: numpy in /home/maryszmary/.local/share/virtualenvs/NLP_DPO_2020-U6tis9ju/lib/python3.6/site-packages (from torchvision) (1.18.2)\n",
      "Installing collected packages: pillow, torchvision\n",
      "Successfully installed pillow-7.1.1 torchvision-0.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 181
    },
    "colab_type": "code",
    "id": "a-WRgs-VFhNt",
    "outputId": "ef897740-7ab8-493d-d611-e8e6ca4a53a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchtext\n",
      "  Downloading torchtext-0.5.0-py3-none-any.whl (73 kB)\n",
      "\u001b[K     |████████████████████████████████| 73 kB 93 kB/s  eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: requests in /home/maryszmary/.local/share/virtualenvs/NLP_DPO_2020-U6tis9ju/lib/python3.6/site-packages (from torchtext) (2.23.0)\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.45.0-py2.py3-none-any.whl (60 kB)\n",
      "\u001b[K     |████████████████████████████████| 60 kB 865 kB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six in /home/maryszmary/.local/share/virtualenvs/NLP_DPO_2020-U6tis9ju/lib/python3.6/site-packages (from torchtext) (1.14.0)\n",
      "Requirement already satisfied: numpy in /home/maryszmary/.local/share/virtualenvs/NLP_DPO_2020-U6tis9ju/lib/python3.6/site-packages (from torchtext) (1.18.2)\n",
      "Requirement already satisfied: torch in /home/maryszmary/.local/share/virtualenvs/NLP_DPO_2020-U6tis9ju/lib/python3.6/site-packages (from torchtext) (1.4.0)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0 MB 15.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /home/maryszmary/.local/share/virtualenvs/NLP_DPO_2020-U6tis9ju/lib/python3.6/site-packages (from requests->torchtext) (2020.4.5.1)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/maryszmary/.local/share/virtualenvs/NLP_DPO_2020-U6tis9ju/lib/python3.6/site-packages (from requests->torchtext) (1.25.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/maryszmary/.local/share/virtualenvs/NLP_DPO_2020-U6tis9ju/lib/python3.6/site-packages (from requests->torchtext) (2.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/maryszmary/.local/share/virtualenvs/NLP_DPO_2020-U6tis9ju/lib/python3.6/site-packages (from requests->torchtext) (3.0.4)\n",
      "Installing collected packages: tqdm, sentencepiece, torchtext\n",
      "Successfully installed sentencepiece-0.1.85 torchtext-0.5.0 tqdm-4.45.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pB7uZ5L7FhN3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Downloading spacy-2.2.4-cp36-cp36m-manylinux1_x86_64.whl (10.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 10.6 MB 73 kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting thinc==7.4.0\n",
      "  Downloading thinc-7.4.0-cp36-cp36m-manylinux1_x86_64.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 34 kB/s s eta 0:00:01\n",
      "\u001b[?25hCollecting wasabi<1.1.0,>=0.4.0\n",
      "  Downloading wasabi-0.6.0-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/maryszmary/.local/share/virtualenvs/NLP_DPO_2020-U6tis9ju/lib/python3.6/site-packages (from spacy) (4.45.0)\n",
      "Collecting cymem<2.1.0,>=2.0.2\n",
      "  Downloading cymem-2.0.3-cp36-cp36m-manylinux1_x86_64.whl (32 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/maryszmary/.local/share/virtualenvs/NLP_DPO_2020-U6tis9ju/lib/python3.6/site-packages (from spacy) (2.23.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/maryszmary/.local/share/virtualenvs/NLP_DPO_2020-U6tis9ju/lib/python3.6/site-packages (from spacy) (1.18.2)\n",
      "Collecting blis<0.5.0,>=0.4.0\n",
      "  Using cached blis-0.4.1-cp36-cp36m-manylinux1_x86_64.whl (3.7 MB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Using cached murmurhash-1.0.2-cp36-cp36m-manylinux1_x86_64.whl (19 kB)\n",
      "Collecting catalogue<1.1.0,>=0.0.7\n",
      "  Downloading catalogue-1.0.0-py2.py3-none-any.whl (7.7 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2\n",
      "  Using cached preshed-3.0.2-cp36-cp36m-manylinux1_x86_64.whl (119 kB)\n",
      "Collecting srsly<1.1.0,>=1.0.2\n",
      "  Downloading srsly-1.0.2-cp36-cp36m-manylinux1_x86_64.whl (185 kB)\n",
      "\u001b[K     |████████████████████████████████| 185 kB 9.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting plac<1.2.0,>=0.9.6\n",
      "  Using cached plac-1.1.3-py2.py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: setuptools in /home/maryszmary/.local/share/virtualenvs/NLP_DPO_2020-U6tis9ju/lib/python3.6/site-packages (from spacy) (46.1.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/maryszmary/.local/share/virtualenvs/NLP_DPO_2020-U6tis9ju/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/maryszmary/.local/share/virtualenvs/NLP_DPO_2020-U6tis9ju/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.4.5.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/maryszmary/.local/share/virtualenvs/NLP_DPO_2020-U6tis9ju/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.9)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/maryszmary/.local/share/virtualenvs/NLP_DPO_2020-U6tis9ju/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.25.8)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /home/maryszmary/.local/share/virtualenvs/NLP_DPO_2020-U6tis9ju/lib/python3.6/site-packages (from catalogue<1.1.0,>=0.0.7->spacy) (1.6.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/maryszmary/.local/share/virtualenvs/NLP_DPO_2020-U6tis9ju/lib/python3.6/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.1.0)\n",
      "Installing collected packages: cymem, murmurhash, preshed, srsly, wasabi, blis, catalogue, plac, thinc, spacy\n",
      "Successfully installed blis-0.4.1 catalogue-1.0.0 cymem-2.0.3 murmurhash-1.0.2 plac-1.1.3 preshed-3.0.2 spacy-2.2.4 srsly-1.0.2 thinc-7.4.0 wasabi-0.6.0\n"
     ]
    }
   ],
   "source": [
    "# Поставим spacy для предобработки данных\n",
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QLGeXcUjFhN8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en_core_web_sm==2.2.5\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz (12.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 12.0 MB 1.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /home/maryszmary/.local/share/virtualenvs/NLP_DPO_2020-U6tis9ju/lib/python3.6/site-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /home/maryszmary/.local/share/virtualenvs/NLP_DPO_2020-U6tis9ju/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.6.0)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /home/maryszmary/.local/share/virtualenvs/NLP_DPO_2020-U6tis9ju/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/maryszmary/.local/share/virtualenvs/NLP_DPO_2020-U6tis9ju/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/maryszmary/.local/share/virtualenvs/NLP_DPO_2020-U6tis9ju/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.3)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /home/maryszmary/.local/share/virtualenvs/NLP_DPO_2020-U6tis9ju/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/maryszmary/.local/share/virtualenvs/NLP_DPO_2020-U6tis9ju/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.45.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/maryszmary/.local/share/virtualenvs/NLP_DPO_2020-U6tis9ju/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.18.2)\n",
      "Requirement already satisfied: setuptools in /home/maryszmary/.local/share/virtualenvs/NLP_DPO_2020-U6tis9ju/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (46.1.3)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /home/maryszmary/.local/share/virtualenvs/NLP_DPO_2020-U6tis9ju/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
      "Requirement already satisfied: thinc==7.4.0 in /home/maryszmary/.local/share/virtualenvs/NLP_DPO_2020-U6tis9ju/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /home/maryszmary/.local/share/virtualenvs/NLP_DPO_2020-U6tis9ju/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/maryszmary/.local/share/virtualenvs/NLP_DPO_2020-U6tis9ju/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/maryszmary/.local/share/virtualenvs/NLP_DPO_2020-U6tis9ju/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /home/maryszmary/.local/share/virtualenvs/NLP_DPO_2020-U6tis9ju/lib/python3.6/site-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.6.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/maryszmary/.local/share/virtualenvs/NLP_DPO_2020-U6tis9ju/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/maryszmary/.local/share/virtualenvs/NLP_DPO_2020-U6tis9ju/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.25.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/maryszmary/.local/share/virtualenvs/NLP_DPO_2020-U6tis9ju/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.4.5.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/maryszmary/.local/share/virtualenvs/NLP_DPO_2020-U6tis9ju/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.9)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/maryszmary/.local/share/virtualenvs/NLP_DPO_2020-U6tis9ju/lib/python3.6/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.1.0)\n",
      "Building wheels for collected packages: en-core-web-sm\n",
      "  Building wheel for en-core-web-sm (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for en-core-web-sm: filename=en_core_web_sm-2.2.5-py3-none-any.whl size=12011738 sha256=4f93ee9f0448a2508b5f1b07d5f46ebeabc63290370d84ec384afa45f6ea701a\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-gas8caiv/wheels/b5/94/56/596daa677d7e91038cbddfcf32b591d0c915a1b3a3e3d3c79d\n",
      "Successfully built en-core-web-sm\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-2.2.5\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
      "/home/maryszmary/.local/share/virtualenvs/NLP_DPO_2020-U6tis9ju/lib/python3.6/site-packages/en_core_web_sm\n",
      "-->\n",
      "/home/maryszmary/.local/share/virtualenvs/NLP_DPO_2020-U6tis9ju/lib/python3.6/site-packages/spacy/data/en\n",
      "You can now load the model via spacy.load('en')\n",
      "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /home/maryszmary/.local/share/virtualenvs/NLP_DPO_2020-U6tis9ju/lib/python3.6/site-packages (2.2.5)\n",
      "Requirement already satisfied: spacy>=2.2.2 in /home/maryszmary/.local/share/virtualenvs/NLP_DPO_2020-U6tis9ju/lib/python3.6/site-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/maryszmary/.local/share/virtualenvs/NLP_DPO_2020-U6tis9ju/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.3)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /home/maryszmary/.local/share/virtualenvs/NLP_DPO_2020-U6tis9ju/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/maryszmary/.local/share/virtualenvs/NLP_DPO_2020-U6tis9ju/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /home/maryszmary/.local/share/virtualenvs/NLP_DPO_2020-U6tis9ju/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/maryszmary/.local/share/virtualenvs/NLP_DPO_2020-U6tis9ju/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/maryszmary/.local/share/virtualenvs/NLP_DPO_2020-U6tis9ju/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.18.2)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /home/maryszmary/.local/share/virtualenvs/NLP_DPO_2020-U6tis9ju/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.6.0)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /home/maryszmary/.local/share/virtualenvs/NLP_DPO_2020-U6tis9ju/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /home/maryszmary/.local/share/virtualenvs/NLP_DPO_2020-U6tis9ju/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
      "Requirement already satisfied: thinc==7.4.0 in /home/maryszmary/.local/share/virtualenvs/NLP_DPO_2020-U6tis9ju/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/maryszmary/.local/share/virtualenvs/NLP_DPO_2020-U6tis9ju/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/maryszmary/.local/share/virtualenvs/NLP_DPO_2020-U6tis9ju/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.45.0)\n",
      "Requirement already satisfied: setuptools in /home/maryszmary/.local/share/virtualenvs/NLP_DPO_2020-U6tis9ju/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (46.1.3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /home/maryszmary/.local/share/virtualenvs/NLP_DPO_2020-U6tis9ju/lib/python3.6/site-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.6.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/maryszmary/.local/share/virtualenvs/NLP_DPO_2020-U6tis9ju/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.4.5.1)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/maryszmary/.local/share/virtualenvs/NLP_DPO_2020-U6tis9ju/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.25.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/maryszmary/.local/share/virtualenvs/NLP_DPO_2020-U6tis9ju/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/maryszmary/.local/share/virtualenvs/NLP_DPO_2020-U6tis9ju/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/maryszmary/.local/share/virtualenvs/NLP_DPO_2020-U6tis9ju/lib/python3.6/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.1.0)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "# загрузим данные для spacy\n",
    "!python -m spacy download en\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QaPk16PLmgnw"
   },
   "outputs": [],
   "source": [
    "# import spacy\n",
    "#import en\n",
    "# en_nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FLGAJBxfFhN_"
   },
   "source": [
    "Загрузим датасет и получим из него выборку:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "xsHAXknhFhOA",
    "outputId": "9bd45015-c43a-4076-bc27-012043df20de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.0\n",
      "downloading aclImdb_v1.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [00:17<00:00, 4.81MB/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "\n",
    "print(torch.__version__)\n",
    "\n",
    "SEED = 0\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "\n",
    "TEXT = data.Field(tokenize='spacy')\n",
    "LABEL = data.LabelField()\n",
    "\n",
    "train_src, test = datasets.IMDB.splits(TEXT, LABEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AJl0ZOPBElSE"
   },
   "source": [
    "Попробуем обучить простую CNN на векторах слов. С учётом того, что в коллекции 100К уникальных слов, и векторы получатся достаточно громоздкие, урежем коллекцию до 25К слов, для всех прочих заведя токен unk (unknown). Кроме того, разобьём обучающий сет на обучение и валидацию для настройки параметров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6nuZQIq1FhOl"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "train, valid = train_src.split(random_state=random.seed(SEED))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yf2viKyOE5FF"
   },
   "source": [
    "Опишем функцию подсчёта accuracy, а также функции обучения и применения сети:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VQo4PuPzFhPE"
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def binary_accuracy(preds, y):\n",
    "    rounded_preds = torch.round(F.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float()\n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jepSRNlkFhPI"
   },
   "outputs": [],
   "source": [
    "def train_func(model, iterator, optimizer, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        predictions = model(batch.text.cuda()).squeeze(1)\n",
    "\n",
    "        loss = criterion(predictions.float(), batch.label.float().cuda())\n",
    "        acc = binary_accuracy(predictions.float(), batch.label.float().cuda())\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss\n",
    "        epoch_acc += acc\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nb0KPBl8FhPL"
   },
   "outputs": [],
   "source": [
    "def evaluate_func(model, iterator, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            predictions = model(batch.text.cuda()).squeeze(1)\n",
    "\n",
    "            loss = criterion(predictions.float(), batch.label.float().cuda())\n",
    "            acc = binary_accuracy(predictions.float(), batch.label.float().cuda())\n",
    "\n",
    "            epoch_loss += loss\n",
    "            epoch_acc += acc\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UHEDOjrAFhP5"
   },
   "source": [
    "Для создания свёрточного слоя воспользуемся nn.Conv2d, in_channels в нашем случае один (текст), out_channels -- это число число фильтров и размер ядер всех фильтров. Каждый фильтр будет иметь размерность [n x размерность эмбеддинга], где n - размер обрабатываемой n-граммы.\n",
    "\n",
    "Важно, что предложения имели длину не меньше размера самого большого из используемых фильтров (здесь это не страшно, поскольку в используемых данных нет текстов, состоящих из пяти и менее слов)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yb5g3czaFhP6"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.conv_0 = nn.Conv2d(in_channels=1, out_channels=n_filters, kernel_size=(filter_sizes[0], embedding_dim))\n",
    "        self.conv_1 = nn.Conv2d(in_channels=1, out_channels=n_filters, kernel_size=(filter_sizes[1], embedding_dim))\n",
    "        self.conv_2 = nn.Conv2d(in_channels=1, out_channels=n_filters, kernel_size=(filter_sizes[2], embedding_dim))\n",
    "        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #x = [sent len, batch size]\n",
    "        x = x.permute(1, 0)\n",
    "                \n",
    "        #x = [batch size, sent len]\n",
    "        embedded = self.embedding(x)\n",
    "                \n",
    "        #embedded = [batch size, sent len, emb dim]\n",
    "        embedded = embedded.unsqueeze(1)\n",
    "        \n",
    "        #embedded = [batch size, 1, sent len, emb dim]\n",
    "        conved_0 = F.relu(self.conv_0(embedded).squeeze(3))\n",
    "        conved_1 = F.relu(self.conv_1(embedded).squeeze(3))\n",
    "        conved_2 = F.relu(self.conv_2(embedded).squeeze(3))\n",
    "            \n",
    "        #conv_n = [batch size, n_filters, sent len - filter_sizes[n]]\n",
    "        pooled_0 = F.max_pool1d(conved_0, conved_0.shape[2]).squeeze(2)\n",
    "        pooled_1 = F.max_pool1d(conved_1, conved_1.shape[2]).squeeze(2)\n",
    "        pooled_2 = F.max_pool1d(conved_2, conved_2.shape[2]).squeeze(2)\n",
    "        \n",
    "        #pooled_n = [batch size, n_filters]\n",
    "        cat = self.dropout(torch.cat((pooled_0, pooled_1, pooled_2), dim=1))\n",
    "\n",
    "        #cat = [batch size, n_filters * len(filter_sizes)]\n",
    "        return self.fc(cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e_xPva9zFhP8"
   },
   "source": [
    "Сейчас мы можем использовать только три различных фильтра, хотелось бы больше. Вообще, можно воспользоваться `nn.ModuleList`, чтобы создать слои списком и сделать так, чтобы фильтров создавалось по количеству элементов в filter_sizes. [(Как здесь).](https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/4%20-%20Convolutional%20Sentiment%20Analysis.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_eWasooHFhQA"
   },
   "source": [
    "Построим словарь и загрузим предобученные эмбеддинги:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "pWlPRIqHFhQD",
    "outputId": "d718244c-a2a0-4c2b-b245-4867a2e143a8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".vector_cache/glove.6B.zip: 862MB [06:30, 2.21MB/s]                          \n",
      "100%|█████████▉| 398168/400000 [00:20<00:00, 18916.18it/s]"
     ]
    }
   ],
   "source": [
    "TEXT.build_vocab(train, max_size=25000, vectors=\"glove.6B.100d\")\n",
    "LABEL.build_vocab(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4Q_Yvs_gFhQB"
   },
   "outputs": [],
   "source": [
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 100\n",
    "N_FILTERS = 100\n",
    "FILTER_SIZES = [3,4,5]\n",
    "OUTPUT_DIM = 1\n",
    "DROPOUT = 0.5\n",
    "\n",
    "model = CNN(INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145
    },
    "colab_type": "code",
    "id": "18Vk11CaZG-u",
    "outputId": "bcbeb0a0-5f20-4e8f-eb5c-9e50c0bcb07e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n",
       "        ...,\n",
       "        [ 0.0501, -0.0960, -0.1318,  ...,  0.2636, -0.5630, -0.3210],\n",
       "        [-0.7064, -0.1308, -0.0430,  ..., -1.0220,  0.7037, -0.3897],\n",
       "        [ 0.6287, -0.4265,  0.1259,  ...,  0.7481,  0.5336, -0.3273]])"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_embeddings = TEXT.vocab.vectors\n",
    "model.embedding.weight.data.copy_(pretrained_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VnFgj1oRGl4k"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE  = 64\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train, valid, test), \n",
    "    batch_size=BATCH_SIZE, \n",
    "    sort_key=lambda x: len(x.text), \n",
    "    repeat=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AmWIaqIbFhQF"
   },
   "source": [
    "Используя определённые ранее функции, запустим обучение с оптимизатором Adam и оценим качество на валидации и тесте:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1Yqwwc5rBc5L"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "np-BTnydFhQF"
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 108
    },
    "colab_type": "code",
    "id": "XZC7S33pFhQH",
    "outputId": "f17fe4d4-1eea-45e1-b49f-07fa6d5e736f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "100%|█████████▉| 398168/400000 [00:40<00:00, 18916.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01, Train Loss: 0.500, Train Acc: 74.34%, Val. Loss: 0.353, Val. Acc: 84.64%\n",
      "Epoch: 02, Train Loss: 0.302, Train Acc: 86.95%, Val. Loss: 0.305, Val. Acc: 86.98%\n",
      "Epoch: 03, Train Loss: 0.216, Train Acc: 91.73%, Val. Loss: 0.279, Val. Acc: 88.61%\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 5\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss, train_acc = train_func(model, train_iterator, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluate_func(model, valid_iterator, criterion)\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02}, Train Loss: {train_loss:.3f}, Train Acc: {train_acc*100:.2f}%, Val. Loss: {valid_loss:.3f}, Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bXQYQCLCFhQJ"
   },
   "outputs": [],
   "source": [
    "test_loss , test_acc = evaluate_func(model, test_iterator, criterion)\n",
    "print(f'Test Loss: {test_loss:.3f}, Test Acc: {test_acc*100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "cnn_classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
